// Package engineapi provides primitives to interact with the openapi HTTP API.
//
// Code generated by github.com/oapi-codegen/oapi-codegen/v2 version v2.5.0 DO NOT EDIT.
package engineapi

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"strings"
	"time"

	"github.com/oapi-codegen/runtime"
)

// Defines values for CrawlCreateRequestFormat.
const (
	CrawlCreateRequestFormatHtml     CrawlCreateRequestFormat = "html"
	CrawlCreateRequestFormatMarkdown CrawlCreateRequestFormat = "markdown"
)

// Defines values for CrawlCreateRequestProxyMode.
const (
	CrawlCreateRequestProxyModeOff         CrawlCreateRequestProxyMode = "off"
	CrawlCreateRequestProxyModeResidential CrawlCreateRequestProxyMode = "residential"
	CrawlCreateRequestProxyModeSharedPool  CrawlCreateRequestProxyMode = "shared_pool"
)

// Defines values for CrawlStatusResponseStatus.
const (
	CrawlStatusResponseStatusCompleted  CrawlStatusResponseStatus = "completed"
	CrawlStatusResponseStatusFailed     CrawlStatusResponseStatus = "failed"
	CrawlStatusResponseStatusPending    CrawlStatusResponseStatus = "pending"
	CrawlStatusResponseStatusProcessing CrawlStatusResponseStatus = "processing"
)

// Defines values for GoogleTrendsStatusResponseStatus.
const (
	GoogleTrendsStatusResponseStatusCompleted  GoogleTrendsStatusResponseStatus = "completed"
	GoogleTrendsStatusResponseStatusFailed     GoogleTrendsStatusResponseStatus = "failed"
	GoogleTrendsStatusResponseStatusProcessing GoogleTrendsStatusResponseStatus = "processing"
)

// Defines values for ParseCreateRequestOutputFormat.
const (
	ParseCreateRequestOutputFormatCsv      ParseCreateRequestOutputFormat = "csv"
	ParseCreateRequestOutputFormatJson     ParseCreateRequestOutputFormat = "json"
	ParseCreateRequestOutputFormatMarkdown ParseCreateRequestOutputFormat = "markdown"
	ParseCreateRequestOutputFormatXml      ParseCreateRequestOutputFormat = "xml"
	ParseCreateRequestOutputFormatYaml     ParseCreateRequestOutputFormat = "yaml"
)

// Defines values for ParseResponseWorkflowStatus.
const (
	Analyzing  ParseResponseWorkflowStatus = "analyzing"
	Completed  ParseResponseWorkflowStatus = "completed"
	Crawling   ParseResponseWorkflowStatus = "crawling"
	Extracting ParseResponseWorkflowStatus = "extracting"
	Failed     ParseResponseWorkflowStatus = "failed"
	Formatting ParseResponseWorkflowStatus = "formatting"
	Scraping   ParseResponseWorkflowStatus = "scraping"
)

// Defines values for GetV1ScrapeParamsFormat.
const (
	Links    GetV1ScrapeParamsFormat = "links"
	Markdown GetV1ScrapeParamsFormat = "markdown"
)

// Defines values for GetV1ScrapeParamsProxyMode.
const (
	GetV1ScrapeParamsProxyModeOff         GetV1ScrapeParamsProxyMode = "off"
	GetV1ScrapeParamsProxyModeResidential GetV1ScrapeParamsProxyMode = "residential"
	GetV1ScrapeParamsProxyModeSharedPool  GetV1ScrapeParamsProxyMode = "shared_pool"
)

// AnalyzeResponse defines model for AnalyzeResponse.
type AnalyzeResponse struct {
	// Country Country code used for scraping
	Country string `json:"country"`

	// Error Error message if scraping failed
	Error *string `json:"error,omitempty"`

	// ScrapedAt When the data was scraped
	ScrapedAt time.Time `json:"scraped_at"`

	// ScrapingDuration Time taken to scrape (e.g., "1500ms")
	ScrapingDuration *string `json:"scraping_duration,omitempty"`

	// Success Whether the scraping was successful
	Success bool `json:"success"`

	// TimeRange Time range string (e.g., "24h")
	TimeRange string `json:"time_range"`

	// TotalTrends Total number of trends found
	TotalTrends int `json:"total_trends"`

	// Trends List of trending topics
	Trends *[]TrendData `json:"trends,omitempty"`
}

// CrawlCreateRequest defines model for CrawlCreateRequest.
type CrawlCreateRequest struct {
	Depth *int `json:"depth,omitempty"`

	// EnableBotProtection Enable anti-bot detection and pivoting
	EnableBotProtection *bool                     `json:"enable_bot_protection,omitempty"`
	Format              *CrawlCreateRequestFormat `json:"format,omitempty"`

	// Fresh Bypass cache and fetch fresh content
	Fresh             *bool `json:"fresh,omitempty"`
	IncludeHtml       *bool `json:"include_html,omitempty"`
	IncludeSubdomains *bool `json:"include_subdomains,omitempty"`
	LinkLimit         *int  `json:"link_limit,omitempty"`

	// MaxConsecutiveErrors Max consecutive errors before pivoting strategy
	MaxConsecutiveErrors *int `json:"max_consecutive_errors,omitempty"`

	// Patterns URL patterns to match (e.g., ["/blog/*", "/docs/*"])
	Patterns *[]string `json:"patterns,omitempty"`

	// ProxyMode Proxy rotation mode
	ProxyMode *CrawlCreateRequestProxyMode `json:"proxy_mode,omitempty"`

	// ProxyRegion ISO country code (e.g., "us", "eu", "gb")
	ProxyRegion *string `json:"proxy_region,omitempty"`

	// ProxySession Sticky session key for proxy consistency
	ProxySession *string `json:"proxy_session,omitempty"`
	RenderJs     *bool   `json:"render_js,omitempty"`

	// RotateUserAgent Enable user agent rotation
	RotateUserAgent *bool  `json:"rotate_user_agent,omitempty"`
	Url             string `json:"url"`

	// UserAgent Specific user agent to use (selected by backend)
	UserAgent *string `json:"user_agent,omitempty"`

	// WaitForSelectors CSS selectors to wait for before considering page loaded (for dynamic content)
	WaitForSelectors *[]string `json:"wait_for_selectors,omitempty"`

	// WebhookHeaders Optional HTTP headers to include in webhook requests
	WebhookHeaders *map[string]string `json:"webhook_headers,omitempty"`

	// WebhookUrl Optional webhook URL to notify when job completes
	WebhookUrl *string `json:"webhook_url,omitempty"`
}

// CrawlCreateRequestFormat defines model for CrawlCreateRequest.Format.
type CrawlCreateRequestFormat string

// CrawlCreateRequestProxyMode Proxy rotation mode
type CrawlCreateRequestProxyMode string

// CrawlCreateResponse defines model for CrawlCreateResponse.
type CrawlCreateResponse struct {
	JobId   string `json:"job_id"`
	Success bool   `json:"success"`
}

// CrawlJobData defines model for CrawlJobData.
type CrawlJobData struct {
	CrawlData  *map[string]PageContent `json:"crawl_data,omitempty"`
	ErrorData  *map[string]string      `json:"error_data,omitempty"`
	RenderJs   *bool                   `json:"render_js,omitempty"`
	Statistics *CrawlStatistics        `json:"statistics,omitempty"`
	Url        *string                 `json:"url,omitempty"`
}

// CrawlStatistics defines model for CrawlStatistics.
type CrawlStatistics struct {
	FailedPages     *int `json:"failed_pages,omitempty"`
	SuccessfulPages *int `json:"successful_pages,omitempty"`
	TotalPages      *int `json:"total_pages,omitempty"`
}

// CrawlStatusResponse defines model for CrawlStatusResponse.
type CrawlStatusResponse struct {
	Data    *CrawlJobData             `json:"data,omitempty"`
	Error   *string                   `json:"error,omitempty"`
	JobId   *string                   `json:"job_id,omitempty"`
	Status  CrawlStatusResponseStatus `json:"status"`
	Success bool                      `json:"success"`
}

// CrawlStatusResponseStatus defines model for CrawlStatusResponse.Status.
type CrawlStatusResponseStatus string

// Error defines model for Error.
type Error struct {
	Error   *string `json:"error,omitempty"`
	Success *bool   `json:"success,omitempty"`
}

// GoogleTrendsJobResponse defines model for GoogleTrendsJobResponse.
type GoogleTrendsJobResponse struct {
	// JobId Unique job identifier
	JobId string `json:"job_id"`

	// Message Status message
	Message string `json:"message"`

	// Success Whether the job was queued successfully
	Success bool `json:"success"`
}

// GoogleTrendsRequest defines model for GoogleTrendsRequest.
type GoogleTrendsRequest struct {
	// Country Country code (e.g., "US", "IN", "GB") or name (optional, auto-inferred from keyword)
	Country *string `json:"country,omitempty"`

	// Hours Time range in hours (optional, default 24)
	Hours *int `json:"hours,omitempty"`

	// Keyword Keyword or title to analyze trends for
	Keyword string `json:"keyword"`

	// Limit Maximum number of results to return (optional, default 25)
	Limit *int `json:"limit,omitempty"`
}

// GoogleTrendsStatusResponse defines model for GoogleTrendsStatusResponse.
type GoogleTrendsStatusResponse struct {
	// JobId Job identifier
	JobId string `json:"job_id"`

	// Message Additional status information
	Message *string `json:"message,omitempty"`

	// Status Current job status
	Status GoogleTrendsStatusResponseStatus `json:"status"`

	// Success Whether the request was successful
	Success bool `json:"success"`
}

// GoogleTrendsStatusResponseStatus Current job status
type GoogleTrendsStatusResponseStatus string

// PageContent defines model for PageContent.
type PageContent struct {
	Markdown string  `json:"markdown"`
	Html     *string `json:"html,omitempty"`

	// Links All discovered links on the page
	Links    []string     `json:"links"`
	Metadata PageMetadata `json:"metadata"`
}

// PageMetadata defines model for PageMetadata.
type PageMetadata struct {
	Canonical          *string `json:"canonical,omitempty"`
	Description        *string `json:"description,omitempty"`
	Favicon            *string `json:"favicon,omitempty"`
	Language           *string `json:"language,omitempty"`
	OgDescription      *string `json:"og_description,omitempty"`
	OgImage            *string `json:"og_image,omitempty"`
	OgSiteName         *string `json:"og_site_name,omitempty"`
	OgTitle            *string `json:"og_title,omitempty"`
	SourceUrl          *string `json:"source_url,omitempty"`
	StatusCode         *int    `json:"status_code,omitempty"`
	Title              *string `json:"title,omitempty"`
	TwitterDescription *string `json:"twitter_description,omitempty"`
	TwitterImage       *string `json:"twitter_image,omitempty"`
	TwitterTitle       *string `json:"twitter_title,omitempty"`
}

// ParseCreateRequest defines model for ParseCreateRequest.
type ParseCreateRequest struct {
	// MaxDepth Maximum crawl depth (if crawling is needed)
	MaxDepth *int `json:"max_depth,omitempty"`

	// MaxPages Maximum pages to process
	MaxPages *int `json:"max_pages,omitempty"`

	// OutputFormat Preferred output format
	OutputFormat *ParseCreateRequestOutputFormat `json:"output_format,omitempty"`

	// Prompt Natural language prompt that may include URLs and extraction instructions
	Prompt string `json:"prompt"`

	// Schema Optional JSON schema for structured output
	Schema *map[string]interface{} `json:"schema,omitempty"`

	// Stream Enable streaming responses for real-time results
	Stream *bool `json:"stream,omitempty"`
}

// ParseCreateRequestOutputFormat Preferred output format
type ParseCreateRequestOutputFormat string

// ParseExamplesResponse defines model for ParseExamplesResponse.
type ParseExamplesResponse struct {
	// Examples Example output specifications
	Examples map[string]map[string]interface{} `json:"examples"`
	Success  bool                              `json:"success"`
}

// ParseResponse defines model for ParseResponse.
type ParseResponse struct {
	// Data Extracted data as JSON object, CSV string, or markdown
	Data interface{} `json:"data,omitempty"`

	// Error Error message if parsing failed
	Error *string `json:"error,omitempty"`

	// ExecutionTime Total execution time in milliseconds
	ExecutionTime *int `json:"execution_time,omitempty"`

	// InputTokens Number of input tokens consumed by LLM calls
	InputTokens *int `json:"input_tokens,omitempty"`

	// OutputTokens Number of output tokens generated by LLM calls
	OutputTokens *int `json:"output_tokens,omitempty"`

	// PagesProcessed Number of pages processed so far
	PagesProcessed *int `json:"pages_processed,omitempty"`

	// PartialResults Incremental results for streaming responses
	PartialResults *[]map[string]interface{} `json:"partial_results,omitempty"`

	// Success Whether the parsing operation succeeded
	Success bool `json:"success"`

	// TotalPages Total pages discovered (if known)
	TotalPages *int `json:"total_pages,omitempty"`

	// TotalTokens Total tokens consumed (input + output)
	TotalTokens *int `json:"total_tokens,omitempty"`

	// WorkflowStatus Current workflow stage
	WorkflowStatus *ParseResponseWorkflowStatus `json:"workflow_status,omitempty"`
}

// ParseResponseWorkflowStatus Current workflow stage
type ParseResponseWorkflowStatus string

// ParseTemplatesResponse defines model for ParseTemplatesResponse.
type ParseTemplatesResponse struct {
	// ContentTypes Supported content types
	ContentTypes []string `json:"content_types"`

	// OutputFormats Supported output formats
	OutputFormats []string `json:"output_formats"`
	Success       bool     `json:"success"`

	// Templates Available templates with descriptions
	Templates map[string]string `json:"templates"`
}

// ScrapeMetadata defines model for ScrapeMetadata.
type ScrapeMetadata struct {
	Canonical          *string `json:"canonical,omitempty"`
	Depth              *int    `json:"depth,omitempty"`
	Description        *string `json:"description,omitempty"`
	Favicon            *string `json:"favicon,omitempty"`
	Language           *string `json:"language,omitempty"`
	OgDescription      *string `json:"og_description,omitempty"`
	OgImage            *string `json:"og_image,omitempty"`
	OgSiteName         *string `json:"og_site_name,omitempty"`
	OgTitle            *string `json:"og_title,omitempty"`
	SourceUrl          *string `json:"source_url,omitempty"`
	StatusCode         *int    `json:"status_code,omitempty"`
	Title              *string `json:"title,omitempty"`
	TwitterDescription *string `json:"twitter_description,omitempty"`
	TwitterImage       *string `json:"twitter_image,omitempty"`
	TwitterTitle       *string `json:"twitter_title,omitempty"`
}

// ScrapeResponse defines model for ScrapeResponse.
type ScrapeResponse struct {
	// Content Markdown content or links depending on format
	Content *string `json:"content,omitempty"`

	// Discovered Number of links discovered
	Discovered *int `json:"discovered,omitempty"`

	// Html HTML content (only if include_html=true)
	Html *string `json:"html,omitempty"`

	// Links All discovered links on the page (always included)
	Links    []string       `json:"links"`
	Metadata ScrapeMetadata `json:"metadata"`
	Success  bool           `json:"success"`
	Title    *string        `json:"title,omitempty"`
	Url      string         `json:"url"`
}

// TrendData defines model for TrendData.
type TrendData struct {
	// Country Country code
	Country string `json:"country"`

	// Rank Trend ranking position
	Rank int `json:"rank"`

	// ScrapedAt When this trend was scraped
	ScrapedAt time.Time `json:"scraped_at"`

	// TimeRange Time range (e.g., "24h")
	TimeRange string `json:"time_range"`

	// Title Trend title/topic
	Title string `json:"title"`
}

// BadRequest defines model for BadRequest.
type BadRequest = Error

// Forbidden defines model for Forbidden.
type Forbidden = Error

// InternalError defines model for InternalError.
type InternalError = Error

// NotFound defines model for NotFound.
type NotFound = Error

// RequestTimeout defines model for RequestTimeout.
type RequestTimeout = Error

// TooManyRequests defines model for TooManyRequests.
type TooManyRequests = Error

// UnprocessableEntity defines model for UnprocessableEntity.
type UnprocessableEntity = Error

// GetV1AnalyzeParams defines parameters for GetV1Analyze.
type GetV1AnalyzeParams struct {
	JobId string `form:"job_id" json:"job_id"`
}

// GetV1ScrapeParams defines parameters for GetV1Scrape.
type GetV1ScrapeParams struct {
	Url                  string                      `form:"url" json:"url"`
	Format               *GetV1ScrapeParamsFormat    `form:"format,omitempty" json:"format,omitempty"`
	Depth                *int                        `form:"depth,omitempty" json:"depth,omitempty"`
	MaxLinks             *int                        `form:"max_links,omitempty" json:"max_links,omitempty"`
	RenderJs             *bool                       `form:"render_js,omitempty" json:"render_js,omitempty"`
	IncludeHtml          *bool                       `form:"include_html,omitempty" json:"include_html,omitempty"`
	Fresh                *bool                       `form:"fresh,omitempty" json:"fresh,omitempty"`
	ProxyMode            *GetV1ScrapeParamsProxyMode `form:"proxy_mode,omitempty" json:"proxy_mode,omitempty"`
	ProxyRegion          *string                     `form:"proxy_region,omitempty" json:"proxy_region,omitempty"`
	ProxySession         *string                     `form:"proxy_session,omitempty" json:"proxy_session,omitempty"`
	RotateUserAgent      *bool                       `form:"rotate_user_agent,omitempty" json:"rotate_user_agent,omitempty"`
	EnableBotProtection  *bool                       `form:"enable_bot_protection,omitempty" json:"enable_bot_protection,omitempty"`
	MaxConsecutiveErrors *int                        `form:"max_consecutive_errors,omitempty" json:"max_consecutive_errors,omitempty"`
	UserAgent            *string                     `form:"user_agent,omitempty" json:"user_agent,omitempty"`
	WaitForSelectors     *[]string                   `form:"wait_for_selectors,omitempty" json:"wait_for_selectors,omitempty"`
}

// GetV1ScrapeParamsFormat defines parameters for GetV1Scrape.
type GetV1ScrapeParamsFormat string

// GetV1ScrapeParamsProxyMode defines parameters for GetV1Scrape.
type GetV1ScrapeParamsProxyMode string

// PostV1AnalyzeJSONRequestBody defines body for PostV1Analyze for application/json ContentType.
type PostV1AnalyzeJSONRequestBody = GoogleTrendsRequest

// PostV1CrawlJSONRequestBody defines body for PostV1Crawl for application/json ContentType.
type PostV1CrawlJSONRequestBody = CrawlCreateRequest

// PostV1ParseJSONRequestBody defines body for PostV1Parse for application/json ContentType.
type PostV1ParseJSONRequestBody = ParseCreateRequest

// RequestEditorFn  is the function signature for the RequestEditor callback function
type RequestEditorFn func(ctx context.Context, req *http.Request) error

// Doer performs HTTP requests.
//
// The standard http.Client implements this interface.
type HttpRequestDoer interface {
	Do(req *http.Request) (*http.Response, error)
}

// Client which conforms to the OpenAPI3 specification for this service.
type Client struct {
	// The endpoint of the server conforming to this interface, with scheme,
	// https://api.deepmap.com for example. This can contain a path relative
	// to the server, such as https://api.deepmap.com/dev-test, and all the
	// paths in the swagger spec will be appended to the server.
	Server string

	// Doer for performing requests, typically a *http.Client with any
	// customized settings, such as certificate chains.
	Client HttpRequestDoer

	// A list of callbacks for modifying requests which are generated before sending over
	// the network.
	RequestEditors []RequestEditorFn
}

// ClientOption allows setting custom parameters during construction
type ClientOption func(*Client) error

// Creates a new Client, with reasonable defaults
func NewClient(server string, opts ...ClientOption) (*Client, error) {
	// create a client with sane default values
	client := Client{
		Server: server,
	}
	// mutate client and add all optional params
	for _, o := range opts {
		if err := o(&client); err != nil {
			return nil, err
		}
	}
	// ensure the server URL always has a trailing slash
	if !strings.HasSuffix(client.Server, "/") {
		client.Server += "/"
	}
	// create httpClient, if not already present
	if client.Client == nil {
		client.Client = &http.Client{}
	}
	return &client, nil
}

// WithHTTPClient allows overriding the default Doer, which is
// automatically created using http.Client. This is useful for tests.
func WithHTTPClient(doer HttpRequestDoer) ClientOption {
	return func(c *Client) error {
		c.Client = doer
		return nil
	}
}

// WithRequestEditorFn allows setting up a callback function, which will be
// called right before sending the request. This can be used to mutate the request.
func WithRequestEditorFn(fn RequestEditorFn) ClientOption {
	return func(c *Client) error {
		c.RequestEditors = append(c.RequestEditors, fn)
		return nil
	}
}

// The interface specification for the client above.
type ClientInterface interface {
	// GetInternalHealth request
	GetInternalHealth(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetV1Analyze request
	GetV1Analyze(ctx context.Context, params *GetV1AnalyzeParams, reqEditors ...RequestEditorFn) (*http.Response, error)

	// PostV1AnalyzeWithBody request with any body
	PostV1AnalyzeWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	PostV1Analyze(ctx context.Context, body PostV1AnalyzeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// PostV1CrawlWithBody request with any body
	PostV1CrawlWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	PostV1Crawl(ctx context.Context, body PostV1CrawlJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetV1CrawlJobId request
	GetV1CrawlJobId(ctx context.Context, jobId string, reqEditors ...RequestEditorFn) (*http.Response, error)

	// PostV1ParseWithBody request with any body
	PostV1ParseWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error)

	PostV1Parse(ctx context.Context, body PostV1ParseJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetV1ParseExamples request
	GetV1ParseExamples(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetV1ParseTemplates request
	GetV1ParseTemplates(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error)

	// GetV1Scrape request
	GetV1Scrape(ctx context.Context, params *GetV1ScrapeParams, reqEditors ...RequestEditorFn) (*http.Response, error)
}

func (c *Client) GetInternalHealth(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetInternalHealthRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetV1Analyze(ctx context.Context, params *GetV1AnalyzeParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetV1AnalyzeRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) PostV1AnalyzeWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewPostV1AnalyzeRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) PostV1Analyze(ctx context.Context, body PostV1AnalyzeJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewPostV1AnalyzeRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) PostV1CrawlWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewPostV1CrawlRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) PostV1Crawl(ctx context.Context, body PostV1CrawlJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewPostV1CrawlRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetV1CrawlJobId(ctx context.Context, jobId string, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetV1CrawlJobIdRequest(c.Server, jobId)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) PostV1ParseWithBody(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewPostV1ParseRequestWithBody(c.Server, contentType, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) PostV1Parse(ctx context.Context, body PostV1ParseJSONRequestBody, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewPostV1ParseRequest(c.Server, body)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetV1ParseExamples(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetV1ParseExamplesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetV1ParseTemplates(ctx context.Context, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetV1ParseTemplatesRequest(c.Server)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

func (c *Client) GetV1Scrape(ctx context.Context, params *GetV1ScrapeParams, reqEditors ...RequestEditorFn) (*http.Response, error) {
	req, err := NewGetV1ScrapeRequest(c.Server, params)
	if err != nil {
		return nil, err
	}
	req = req.WithContext(ctx)
	if err := c.applyEditors(ctx, req, reqEditors); err != nil {
		return nil, err
	}
	return c.Client.Do(req)
}

// NewGetInternalHealthRequest generates requests for GetInternalHealth
func NewGetInternalHealthRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/internal/health")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetV1AnalyzeRequest generates requests for GetV1Analyze
func NewGetV1AnalyzeRequest(server string, params *GetV1AnalyzeParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/analyze")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "job_id", runtime.ParamLocationQuery, params.JobId); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewPostV1AnalyzeRequest calls the generic PostV1Analyze builder with application/json body
func NewPostV1AnalyzeRequest(server string, body PostV1AnalyzeJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewPostV1AnalyzeRequestWithBody(server, "application/json", bodyReader)
}

// NewPostV1AnalyzeRequestWithBody generates requests for PostV1Analyze with any type of body
func NewPostV1AnalyzeRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/analyze")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewPostV1CrawlRequest calls the generic PostV1Crawl builder with application/json body
func NewPostV1CrawlRequest(server string, body PostV1CrawlJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewPostV1CrawlRequestWithBody(server, "application/json", bodyReader)
}

// NewPostV1CrawlRequestWithBody generates requests for PostV1Crawl with any type of body
func NewPostV1CrawlRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/crawl")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetV1CrawlJobIdRequest generates requests for GetV1CrawlJobId
func NewGetV1CrawlJobIdRequest(server string, jobId string) (*http.Request, error) {
	var err error

	var pathParam0 string

	pathParam0, err = runtime.StyleParamWithLocation("simple", false, "jobId", runtime.ParamLocationPath, jobId)
	if err != nil {
		return nil, err
	}

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/crawl/%s", pathParam0)
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewPostV1ParseRequest calls the generic PostV1Parse builder with application/json body
func NewPostV1ParseRequest(server string, body PostV1ParseJSONRequestBody) (*http.Request, error) {
	var bodyReader io.Reader
	buf, err := json.Marshal(body)
	if err != nil {
		return nil, err
	}
	bodyReader = bytes.NewReader(buf)
	return NewPostV1ParseRequestWithBody(server, "application/json", bodyReader)
}

// NewPostV1ParseRequestWithBody generates requests for PostV1Parse with any type of body
func NewPostV1ParseRequestWithBody(server string, contentType string, body io.Reader) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/parse")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", queryURL.String(), body)
	if err != nil {
		return nil, err
	}

	req.Header.Add("Content-Type", contentType)

	return req, nil
}

// NewGetV1ParseExamplesRequest generates requests for GetV1ParseExamples
func NewGetV1ParseExamplesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/parse/examples")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetV1ParseTemplatesRequest generates requests for GetV1ParseTemplates
func NewGetV1ParseTemplatesRequest(server string) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/parse/templates")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

// NewGetV1ScrapeRequest generates requests for GetV1Scrape
func NewGetV1ScrapeRequest(server string, params *GetV1ScrapeParams) (*http.Request, error) {
	var err error

	serverURL, err := url.Parse(server)
	if err != nil {
		return nil, err
	}

	operationPath := fmt.Sprintf("/v1/scrape")
	if operationPath[0] == '/' {
		operationPath = "." + operationPath
	}

	queryURL, err := serverURL.Parse(operationPath)
	if err != nil {
		return nil, err
	}

	if params != nil {
		queryValues := queryURL.Query()

		if queryFrag, err := runtime.StyleParamWithLocation("form", true, "url", runtime.ParamLocationQuery, params.Url); err != nil {
			return nil, err
		} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
			return nil, err
		} else {
			for k, v := range parsed {
				for _, v2 := range v {
					queryValues.Add(k, v2)
				}
			}
		}

		if params.Format != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "format", runtime.ParamLocationQuery, *params.Format); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.Depth != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "depth", runtime.ParamLocationQuery, *params.Depth); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.MaxLinks != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "max_links", runtime.ParamLocationQuery, *params.MaxLinks); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.RenderJs != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "render_js", runtime.ParamLocationQuery, *params.RenderJs); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.IncludeHtml != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "include_html", runtime.ParamLocationQuery, *params.IncludeHtml); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.Fresh != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "fresh", runtime.ParamLocationQuery, *params.Fresh); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.ProxyMode != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "proxy_mode", runtime.ParamLocationQuery, *params.ProxyMode); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.ProxyRegion != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "proxy_region", runtime.ParamLocationQuery, *params.ProxyRegion); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.ProxySession != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "proxy_session", runtime.ParamLocationQuery, *params.ProxySession); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.RotateUserAgent != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "rotate_user_agent", runtime.ParamLocationQuery, *params.RotateUserAgent); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.EnableBotProtection != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "enable_bot_protection", runtime.ParamLocationQuery, *params.EnableBotProtection); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.MaxConsecutiveErrors != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "max_consecutive_errors", runtime.ParamLocationQuery, *params.MaxConsecutiveErrors); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.UserAgent != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "user_agent", runtime.ParamLocationQuery, *params.UserAgent); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		if params.WaitForSelectors != nil {

			if queryFrag, err := runtime.StyleParamWithLocation("form", true, "wait_for_selectors", runtime.ParamLocationQuery, *params.WaitForSelectors); err != nil {
				return nil, err
			} else if parsed, err := url.ParseQuery(queryFrag); err != nil {
				return nil, err
			} else {
				for k, v := range parsed {
					for _, v2 := range v {
						queryValues.Add(k, v2)
					}
				}
			}

		}

		queryURL.RawQuery = queryValues.Encode()
	}

	req, err := http.NewRequest("GET", queryURL.String(), nil)
	if err != nil {
		return nil, err
	}

	return req, nil
}

func (c *Client) applyEditors(ctx context.Context, req *http.Request, additionalEditors []RequestEditorFn) error {
	for _, r := range c.RequestEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	for _, r := range additionalEditors {
		if err := r(ctx, req); err != nil {
			return err
		}
	}
	return nil
}

// ClientWithResponses builds on ClientInterface to offer response payloads
type ClientWithResponses struct {
	ClientInterface
}

// NewClientWithResponses creates a new ClientWithResponses, which wraps
// Client with return type handling
func NewClientWithResponses(server string, opts ...ClientOption) (*ClientWithResponses, error) {
	client, err := NewClient(server, opts...)
	if err != nil {
		return nil, err
	}
	return &ClientWithResponses{client}, nil
}

// WithBaseURL overrides the baseURL.
func WithBaseURL(baseURL string) ClientOption {
	return func(c *Client) error {
		newBaseURL, err := url.Parse(baseURL)
		if err != nil {
			return err
		}
		c.Server = newBaseURL.String()
		return nil
	}
}

// ClientWithResponsesInterface is the interface specification for the client with responses above.
type ClientWithResponsesInterface interface {
	// GetInternalHealthWithResponse request
	GetInternalHealthWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetInternalHealthResponse, error)

	// GetV1AnalyzeWithResponse request
	GetV1AnalyzeWithResponse(ctx context.Context, params *GetV1AnalyzeParams, reqEditors ...RequestEditorFn) (*GetV1AnalyzeResponse, error)

	// PostV1AnalyzeWithBodyWithResponse request with any body
	PostV1AnalyzeWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*PostV1AnalyzeResponse, error)

	PostV1AnalyzeWithResponse(ctx context.Context, body PostV1AnalyzeJSONRequestBody, reqEditors ...RequestEditorFn) (*PostV1AnalyzeResponse, error)

	// PostV1CrawlWithBodyWithResponse request with any body
	PostV1CrawlWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*PostV1CrawlResponse, error)

	PostV1CrawlWithResponse(ctx context.Context, body PostV1CrawlJSONRequestBody, reqEditors ...RequestEditorFn) (*PostV1CrawlResponse, error)

	// GetV1CrawlJobIdWithResponse request
	GetV1CrawlJobIdWithResponse(ctx context.Context, jobId string, reqEditors ...RequestEditorFn) (*GetV1CrawlJobIdResponse, error)

	// PostV1ParseWithBodyWithResponse request with any body
	PostV1ParseWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*PostV1ParseResponse, error)

	PostV1ParseWithResponse(ctx context.Context, body PostV1ParseJSONRequestBody, reqEditors ...RequestEditorFn) (*PostV1ParseResponse, error)

	// GetV1ParseExamplesWithResponse request
	GetV1ParseExamplesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetV1ParseExamplesResponse, error)

	// GetV1ParseTemplatesWithResponse request
	GetV1ParseTemplatesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetV1ParseTemplatesResponse, error)

	// GetV1ScrapeWithResponse request
	GetV1ScrapeWithResponse(ctx context.Context, params *GetV1ScrapeParams, reqEditors ...RequestEditorFn) (*GetV1ScrapeResponse, error)
}

type GetInternalHealthResponse struct {
	Body         []byte
	HTTPResponse *http.Response
}

// Status returns HTTPResponse.Status
func (r GetInternalHealthResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetInternalHealthResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetV1AnalyzeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		union json.RawMessage
	}
	JSON404 *NotFound
}

// Status returns HTTPResponse.Status
func (r GetV1AnalyzeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetV1AnalyzeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type PostV1AnalyzeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *struct {
		union json.RawMessage
	}
	JSON400 *BadRequest
}

// Status returns HTTPResponse.Status
func (r PostV1AnalyzeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r PostV1AnalyzeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type PostV1CrawlResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *CrawlCreateResponse
	JSON400      *BadRequest
}

// Status returns HTTPResponse.Status
func (r PostV1CrawlResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r PostV1CrawlResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetV1CrawlJobIdResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *CrawlStatusResponse
	JSON404      *NotFound
}

// Status returns HTTPResponse.Status
func (r GetV1CrawlJobIdResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetV1CrawlJobIdResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type PostV1ParseResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ParseResponse
	JSON400      *BadRequest
	JSON422      *UnprocessableEntity
	JSON500      *InternalError
}

// Status returns HTTPResponse.Status
func (r PostV1ParseResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r PostV1ParseResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetV1ParseExamplesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ParseExamplesResponse
}

// Status returns HTTPResponse.Status
func (r GetV1ParseExamplesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetV1ParseExamplesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetV1ParseTemplatesResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ParseTemplatesResponse
}

// Status returns HTTPResponse.Status
func (r GetV1ParseTemplatesResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetV1ParseTemplatesResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

type GetV1ScrapeResponse struct {
	Body         []byte
	HTTPResponse *http.Response
	JSON200      *ScrapeResponse
	JSON400      *BadRequest
	JSON403      *Forbidden
	JSON404      *NotFound
	JSON408      *RequestTimeout
	JSON422      *UnprocessableEntity
	JSON429      *TooManyRequests
	JSON500      *InternalError
}

// Status returns HTTPResponse.Status
func (r GetV1ScrapeResponse) Status() string {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.Status
	}
	return http.StatusText(0)
}

// StatusCode returns HTTPResponse.StatusCode
func (r GetV1ScrapeResponse) StatusCode() int {
	if r.HTTPResponse != nil {
		return r.HTTPResponse.StatusCode
	}
	return 0
}

// GetInternalHealthWithResponse request returning *GetInternalHealthResponse
func (c *ClientWithResponses) GetInternalHealthWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetInternalHealthResponse, error) {
	rsp, err := c.GetInternalHealth(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetInternalHealthResponse(rsp)
}

// GetV1AnalyzeWithResponse request returning *GetV1AnalyzeResponse
func (c *ClientWithResponses) GetV1AnalyzeWithResponse(ctx context.Context, params *GetV1AnalyzeParams, reqEditors ...RequestEditorFn) (*GetV1AnalyzeResponse, error) {
	rsp, err := c.GetV1Analyze(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetV1AnalyzeResponse(rsp)
}

// PostV1AnalyzeWithBodyWithResponse request with arbitrary body returning *PostV1AnalyzeResponse
func (c *ClientWithResponses) PostV1AnalyzeWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*PostV1AnalyzeResponse, error) {
	rsp, err := c.PostV1AnalyzeWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParsePostV1AnalyzeResponse(rsp)
}

func (c *ClientWithResponses) PostV1AnalyzeWithResponse(ctx context.Context, body PostV1AnalyzeJSONRequestBody, reqEditors ...RequestEditorFn) (*PostV1AnalyzeResponse, error) {
	rsp, err := c.PostV1Analyze(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParsePostV1AnalyzeResponse(rsp)
}

// PostV1CrawlWithBodyWithResponse request with arbitrary body returning *PostV1CrawlResponse
func (c *ClientWithResponses) PostV1CrawlWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*PostV1CrawlResponse, error) {
	rsp, err := c.PostV1CrawlWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParsePostV1CrawlResponse(rsp)
}

func (c *ClientWithResponses) PostV1CrawlWithResponse(ctx context.Context, body PostV1CrawlJSONRequestBody, reqEditors ...RequestEditorFn) (*PostV1CrawlResponse, error) {
	rsp, err := c.PostV1Crawl(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParsePostV1CrawlResponse(rsp)
}

// GetV1CrawlJobIdWithResponse request returning *GetV1CrawlJobIdResponse
func (c *ClientWithResponses) GetV1CrawlJobIdWithResponse(ctx context.Context, jobId string, reqEditors ...RequestEditorFn) (*GetV1CrawlJobIdResponse, error) {
	rsp, err := c.GetV1CrawlJobId(ctx, jobId, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetV1CrawlJobIdResponse(rsp)
}

// PostV1ParseWithBodyWithResponse request with arbitrary body returning *PostV1ParseResponse
func (c *ClientWithResponses) PostV1ParseWithBodyWithResponse(ctx context.Context, contentType string, body io.Reader, reqEditors ...RequestEditorFn) (*PostV1ParseResponse, error) {
	rsp, err := c.PostV1ParseWithBody(ctx, contentType, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParsePostV1ParseResponse(rsp)
}

func (c *ClientWithResponses) PostV1ParseWithResponse(ctx context.Context, body PostV1ParseJSONRequestBody, reqEditors ...RequestEditorFn) (*PostV1ParseResponse, error) {
	rsp, err := c.PostV1Parse(ctx, body, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParsePostV1ParseResponse(rsp)
}

// GetV1ParseExamplesWithResponse request returning *GetV1ParseExamplesResponse
func (c *ClientWithResponses) GetV1ParseExamplesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetV1ParseExamplesResponse, error) {
	rsp, err := c.GetV1ParseExamples(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetV1ParseExamplesResponse(rsp)
}

// GetV1ParseTemplatesWithResponse request returning *GetV1ParseTemplatesResponse
func (c *ClientWithResponses) GetV1ParseTemplatesWithResponse(ctx context.Context, reqEditors ...RequestEditorFn) (*GetV1ParseTemplatesResponse, error) {
	rsp, err := c.GetV1ParseTemplates(ctx, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetV1ParseTemplatesResponse(rsp)
}

// GetV1ScrapeWithResponse request returning *GetV1ScrapeResponse
func (c *ClientWithResponses) GetV1ScrapeWithResponse(ctx context.Context, params *GetV1ScrapeParams, reqEditors ...RequestEditorFn) (*GetV1ScrapeResponse, error) {
	rsp, err := c.GetV1Scrape(ctx, params, reqEditors...)
	if err != nil {
		return nil, err
	}
	return ParseGetV1ScrapeResponse(rsp)
}

// ParseGetInternalHealthResponse parses an HTTP response from a GetInternalHealthWithResponse call
func ParseGetInternalHealthResponse(rsp *http.Response) (*GetInternalHealthResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetInternalHealthResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	return response, nil
}

// ParseGetV1AnalyzeResponse parses an HTTP response from a GetV1AnalyzeWithResponse call
func ParseGetV1AnalyzeResponse(rsp *http.Response) (*GetV1AnalyzeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetV1AnalyzeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			union json.RawMessage
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParsePostV1AnalyzeResponse parses an HTTP response from a PostV1AnalyzeWithResponse call
func ParsePostV1AnalyzeResponse(rsp *http.Response) (*PostV1AnalyzeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &PostV1AnalyzeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest struct {
			union json.RawMessage
		}
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParsePostV1CrawlResponse parses an HTTP response from a PostV1CrawlWithResponse call
func ParsePostV1CrawlResponse(rsp *http.Response) (*PostV1CrawlResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &PostV1CrawlResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest CrawlCreateResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	}

	return response, nil
}

// ParseGetV1CrawlJobIdResponse parses an HTTP response from a GetV1CrawlJobIdWithResponse call
func ParseGetV1CrawlJobIdResponse(rsp *http.Response) (*GetV1CrawlJobIdResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetV1CrawlJobIdResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest CrawlStatusResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	}

	return response, nil
}

// ParsePostV1ParseResponse parses an HTTP response from a PostV1ParseWithResponse call
func ParsePostV1ParseResponse(rsp *http.Response) (*PostV1ParseResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &PostV1ParseResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ParseResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 422:
		var dest UnprocessableEntity
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON422 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}

// ParseGetV1ParseExamplesResponse parses an HTTP response from a GetV1ParseExamplesWithResponse call
func ParseGetV1ParseExamplesResponse(rsp *http.Response) (*GetV1ParseExamplesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetV1ParseExamplesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ParseExamplesResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	}

	return response, nil
}

// ParseGetV1ParseTemplatesResponse parses an HTTP response from a GetV1ParseTemplatesWithResponse call
func ParseGetV1ParseTemplatesResponse(rsp *http.Response) (*GetV1ParseTemplatesResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetV1ParseTemplatesResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ParseTemplatesResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	}

	return response, nil
}

// ParseGetV1ScrapeResponse parses an HTTP response from a GetV1ScrapeWithResponse call
func ParseGetV1ScrapeResponse(rsp *http.Response) (*GetV1ScrapeResponse, error) {
	bodyBytes, err := io.ReadAll(rsp.Body)
	defer func() { _ = rsp.Body.Close() }()
	if err != nil {
		return nil, err
	}

	response := &GetV1ScrapeResponse{
		Body:         bodyBytes,
		HTTPResponse: rsp,
	}

	switch {
	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 200:
		var dest ScrapeResponse
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON200 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 400:
		var dest BadRequest
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON400 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 403:
		var dest Forbidden
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON403 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 404:
		var dest NotFound
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON404 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 408:
		var dest RequestTimeout
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON408 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 422:
		var dest UnprocessableEntity
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON422 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 429:
		var dest TooManyRequests
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON429 = &dest

	case strings.Contains(rsp.Header.Get("Content-Type"), "json") && rsp.StatusCode == 500:
		var dest InternalError
		if err := json.Unmarshal(bodyBytes, &dest); err != nil {
			return nil, err
		}
		response.JSON500 = &dest

	}

	return response, nil
}
