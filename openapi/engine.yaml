openapi: 3.0.3
info:
  title: Supacrawler Scraper Engine API
  version: 0.1.0
  description: HTTP API for scraping, mapping, crawling, and Google Trends analysis
servers:
- url: http://localhost:8081
  description: Local engine
tags:
- name: health
- name: scrape
- name: jobs
- name: analyze
paths:
  /internal/health:
    get:
      tags: [ health ]
      summary: Health check
      responses:
        '200':
          description: ok
          content:
            text/plain:
              schema:
                type: string
  /v1/scrape:
    get:
      tags: [ scrape ]
      summary: Scrape a single URL
      parameters:
      - in: query
        name: url
        required: true
        schema:
          type: string
          format: uri
      - in: query
        name: format
        schema:
          type: string
          enum: [ markdown, links ]
      - in: query
        name: depth
        schema:
          type: integer
          minimum: 0
      - in: query
        name: max_links
        schema:
          type: integer
          minimum: 0
      - in: query
        name: render_js
        schema:
          type: boolean
      - in: query
        name: include_html
        schema:
          type: boolean
      - in: query
        name: fresh
        schema:
          type: boolean
      - in: query
        name: proxy_mode
        schema:
          type: string
          enum: [ off, shared_pool, residential ]
          default: off
      - in: query
        name: proxy_region
        schema:
          type: string
          description: ISO country code (e.g., "us", "eu", "gb")
      - in: query
        name: proxy_session
        schema:
          type: string
          description: Sticky session key for proxy consistency
      - in: query
        name: rotate_user_agent
        schema:
          type: boolean
          default: true
      - in: query
        name: enable_bot_protection
        schema:
          type: boolean
          default: true
      - in: query
        name: max_consecutive_errors
        schema:
          type: integer
          minimum: 1
          maximum: 20
          default: 5
      - in: query
        name: user_agent
        schema:
          type: string
          description: Specific user agent to use (selected by backend)
      - in: query
        name: wait_for_selectors
        schema:
          type: array
          items:
            type: string
          description: CSS selectors to wait for before considering page loaded (for dynamic content)
      responses:
        '200':
          description: Scrape response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ScrapeResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '408':
          $ref: '#/components/responses/RequestTimeout'
        '422':
          $ref: '#/components/responses/UnprocessableEntity'
        '429':
          $ref: '#/components/responses/TooManyRequests'
        '500':
          $ref: '#/components/responses/InternalError'
  /v1/crawl:
    post:
      tags: [ jobs ]
      summary: Create a crawl job
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CrawlCreateRequest'
      responses:
        '200':
          description: Crawl job created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CrawlCreateResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
  /v1/crawl/{jobId}:
    get:
      tags: [ jobs ]
      summary: Get crawl job status/result
      parameters:
      - in: path
        name: jobId
        required: true
        schema:
          type: string
      responses:
        '200':
          description: Crawl job status
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CrawlStatusResponse'
        '404':
          $ref: '#/components/responses/NotFound'
  /v1/parse:
    post:
      tags: [ parse ]
      summary: Parse HTML or Markdown content using LLM
      description: Extract structured data from HTML or Markdown content with customizable output schemas
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ParseCreateRequest'
      responses:
        '200':
          description: Parse operation result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ParseResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
        '422':
          $ref: '#/components/responses/UnprocessableEntity'
        '500':
          $ref: '#/components/responses/InternalError'
  /v1/parse/templates:
    get:
      tags: [ parse ]
      summary: Get available parse templates
      description: List all available prompt templates with descriptions and supported content types
      responses:
        '200':
          description: Available templates and configuration
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ParseTemplatesResponse'
  /v1/parse/examples:
    get:
      tags: [ parse ]
      summary: Get example output specifications
      description: Get example output schemas for different content types
      responses:
        '200':
          description: Example output specifications
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ParseExamplesResponse'
  /v1/analyze:
    post:
      tags: [ analyze ]
      summary: Analyze Google Trends for a keyword
      description: Perform detailed Google Trends analysis for a specific keyword, including search interest, related queries, rising queries, and regional data
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/GoogleTrendsRequest'
      responses:
        '200':
          description: Keyword analysis data or job queued
          content:
            application/json:
              schema:
                oneOf:
                - $ref: '#/components/schemas/AnalyzeResponse'
                - $ref: '#/components/schemas/GoogleTrendsJobResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
    get:
      tags: [ analyze ]
      summary: Get keyword analysis job status/results
      parameters:
      - in: query
        name: job_id
        required: true
        schema:
          type: string
      responses:
        '200':
          description: Analysis data or job status
          content:
            application/json:
              schema:
                oneOf:
                - $ref: '#/components/schemas/AnalyzeResponse'
                - $ref: '#/components/schemas/GoogleTrendsStatusResponse'
        '404':
          $ref: '#/components/responses/NotFound'

components:
  responses:
    BadRequest:
      description: Bad request
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    Forbidden:
      description: Forbidden - Access denied (e.g., robots.txt disallowed)
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    NotFound:
      description: Not found
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    RequestTimeout:
      description: Request timeout
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    UnprocessableEntity:
      description: Unprocessable entity - Content filtered or invalid
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    TooManyRequests:
      description: Too many requests - Rate limited
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
    InternalError:
      description: Server error
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/Error'
  schemas:
    Error:
      type: object
      properties:
        success:
          type: boolean
          example: false
        error:
          type: string

    ScrapeResponse:
      type: object
      properties:
        success:
          type: boolean
        url:
          type: string
          format: uri
        title:
          type: string
        content:
          type: string
          description: Markdown content or links depending on format
        html:
          type: string
          description: HTML content (only if include_html=true)
        links:
          type: array
          items:
            type: string
          description: All discovered links on the page (always included)
        discovered:
          type: integer
          description: Number of links discovered
        metadata:
          $ref: '#/components/schemas/ScrapeMetadata'
      required: [ success, url, links, metadata ]

    ScrapeMetadata:
      type: object
      properties:
        status_code:
          type: integer
        depth:
          type: integer
        source_url:
          type: string
          format: uri
        title:
          type: string
        description:
          type: string
        language:
          type: string
        canonical:
          type: string
        favicon:
          type: string
        og_title:
          type: string
        og_description:
          type: string
        og_image:
          type: string
        og_site_name:
          type: string
        twitter_title:
          type: string
        twitter_description:
          type: string
        twitter_image:
          type: string

    CrawlCreateRequest:
      type: object
      properties:
        url:
          type: string
          format: uri
        format:
          type: string
          enum: [ markdown, html ]
        depth:
          type: integer
        link_limit:
          type: integer
        include_subdomains:
          type: boolean
        render_js:
          type: boolean
        include_html:
          type: boolean
        fresh:
          type: boolean
          description: Bypass cache and fetch fresh content
        patterns:
          type: array
          items:
            type: string
          description: URL patterns to match (e.g., ["/blog/*", "/docs/*"])
        proxy_mode:
          type: string
          enum: [ off, shared_pool, residential ]
          default: off
          description: Proxy rotation mode
        proxy_region:
          type: string
          description: ISO country code (e.g., "us", "eu", "gb")
        proxy_session:
          type: string
          description: Sticky session key for proxy consistency
        rotate_user_agent:
          type: boolean
          default: true
          description: Enable user agent rotation
        enable_bot_protection:
          type: boolean
          default: true
          description: Enable anti-bot detection and pivoting
        max_consecutive_errors:
          type: integer
          minimum: 1
          maximum: 20
          default: 5
          description: Max consecutive errors before pivoting strategy
        user_agent:
          type: string
          description: Specific user agent to use (selected by backend)
        wait_for_selectors:
          type: array
          items:
            type: string
          description: CSS selectors to wait for before considering page loaded (for dynamic content)
        webhook_url:
          type: string
          format: uri
          description: Optional webhook URL to notify when job completes
        webhook_headers:
          type: object
          additionalProperties:
            type: string
          description: Optional HTTP headers to include in webhook requests
      required: [ url ]

    CrawlCreateResponse:
      type: object
      properties:
        success:
          type: boolean
        job_id:
          type: string
      required: [ success, job_id ]

    CrawlStatusResponse:
      type: object
      properties:
        success:
          type: boolean
        job_id:
          type: string
        status:
          type: string
          enum: [ pending, processing, completed, failed ]
        data:
          $ref: '#/components/schemas/CrawlJobData'
        error:
          type: string
      required: [ success, status ]

    CrawlJobData:
      type: object
      properties:
        url:
          type: string
        crawl_data:
          type: object
          additionalProperties:
            $ref: '#/components/schemas/PageContent'
        error_data:
          type: object
          additionalProperties:
            type: string
        statistics:
          $ref: '#/components/schemas/CrawlStatistics'
        render_js:
          type: boolean

    PageContent:
      type: object
      properties:
        markdown:
          type: string
          x-order: 1
        html:
          type: string
          x-order: 2
        links:
          type: array
          items:
            type: string
          description: All discovered links on the page
          x-order: 3
        metadata:
          $ref: '#/components/schemas/PageMetadata'
          x-order: 4
      required: [ markdown, links, metadata ]

    PageMetadata:
      type: object
      properties:
        title:
          type: string
        status_code:
          type: integer
        description:
          type: string
        language:
          type: string
        canonical:
          type: string
        favicon:
          type: string
        og_title:
          type: string
        og_description:
          type: string
        og_image:
          type: string
        og_site_name:
          type: string
        twitter_title:
          type: string
        twitter_description:
          type: string
        twitter_image:
          type: string
        source_url:
          type: string
          format: uri

    CrawlStatistics:
      type: object
      properties:
        total_pages:
          type: integer
        successful_pages:
          type: integer
        failed_pages:
          type: integer

    ParseCreateRequest:
      type: object
      properties:
        prompt:
          type: string
          description: Natural language prompt that may include URLs and extraction instructions
          example: "Crawl https://example.com/blog and give me the 5 most recent posts in CSV."
        schema:
          type: object
          additionalProperties: true
          description: Optional JSON schema for structured output
          example:
            type: object
            properties:
              posts:
                type: array
                items:
                  type: object
                  properties:
                    title:
                      type: string
                    date:
                      type: string
                    url:
                      type: string
                  required: [ "title", "date", "url" ]
            required: [ "posts" ]
        output_format:
          type: string
          enum: [ json, csv, markdown, xml, yaml ]
          default: json
          description: Preferred output format
        stream:
          type: boolean
          default: false
          description: Enable streaming responses for real-time results
        max_depth:
          type: integer
          minimum: 1
          maximum: 3
          default: 1
          description: Maximum crawl depth (if crawling is needed)
        max_pages:
          type: integer
          minimum: 1
          maximum: 100
          default: 10
          description: Maximum pages to process
      required: [ prompt ]

    ParseResponse:
      type: object
      properties:
        success:
          type: boolean
          description: Whether the parsing operation succeeded
        data:
          description: Extracted data as JSON object, CSV string, or markdown
        workflow_status:
          type: string
          enum: [ analyzing, crawling, scraping, extracting, formatting, completed, failed ]
          description: Current workflow stage
        pages_processed:
          type: integer
          description: Number of pages processed so far
        total_pages:
          type: integer
          description: Total pages discovered (if known)
        partial_results:
          type: array
          items:
            type: object
          description: Incremental results for streaming responses
        execution_time:
          type: integer
          description: Total execution time in milliseconds
        error:
          type: string
          description: Error message if parsing failed
        input_tokens:
          type: integer
          description: Number of input tokens consumed by LLM calls
        output_tokens:
          type: integer
          description: Number of output tokens generated by LLM calls
        total_tokens:
          type: integer
          description: Total tokens consumed (input + output)
      required: [ success ]

    ParseValidationResult:
      type: object
      properties:
        is_valid:
          type: boolean
          description: Whether the response is valid
        format:
          type: string
          enum: [ json, csv ]
          description: Format of the response
        errors:
          type: array
          items:
            type: string
          description: Validation errors
        fields_found:
          type: array
          items:
            type: string
          description: JSON fields discovered
        row_count:
          type: integer
          description: CSV row count
        column_count:
          type: integer
          description: CSV column count
      required: [ is_valid, format, errors ]

    ParseTemplatesResponse:
      type: object
      properties:
        success:
          type: boolean
        templates:
          type: object
          additionalProperties:
            type: string
          description: Available templates with descriptions
        content_types:
          type: array
          items:
            type: string
          description: Supported content types
        output_formats:
          type: array
          items:
            type: string
          description: Supported output formats
      required: [ success, templates, content_types, output_formats ]

    ParseExamplesResponse:
      type: object
      properties:
        success:
          type: boolean
        examples:
          type: object
          additionalProperties:
            type: object
            additionalProperties: true
          description: Example output specifications
      required: [ success, examples ]

    GoogleTrendsRequest:
      type: object
      properties:
        keyword:
          type: string
          description: Keyword or title to analyze trends for
          example: "artificial intelligence"
        country:
          type: string
          description: Country code (e.g., "US", "IN", "GB") or name (optional, auto-inferred from keyword)
          example: "US"
        hours:
          type: integer
          description: Time range in hours (optional, default 24)
          minimum: 1
          example: 24
        limit:
          type: integer
          description: Maximum number of results to return (optional, default 25)
          minimum: 1
          maximum: 100
          example: 25
      required: [ keyword ]

    AnalyzeResponse:
      type: object
      properties:
        success:
          type: boolean
          description: Whether the scraping was successful
        country:
          type: string
          description: Country code used for scraping
        time_range:
          type: string
          description: Time range string (e.g., "24h")
        total_trends:
          type: integer
          description: Total number of trends found
        scraping_duration:
          type: string
          description: Time taken to scrape (e.g., "1500ms")
        scraped_at:
          type: string
          format: date-time
          description: When the data was scraped
        trends:
          type: array
          items:
            $ref: '#/components/schemas/TrendData'
          description: List of trending topics
        error:
          type: string
          description: Error message if scraping failed
      required: [ success, country, time_range, total_trends, scraped_at ]

    TrendData:
      type: object
      properties:
        rank:
          type: integer
          description: Trend ranking position
        title:
          type: string
          description: Trend title/topic
        country:
          type: string
          description: Country code
        time_range:
          type: string
          description: Time range (e.g., "24h")
        scraped_at:
          type: string
          format: date-time
          description: When this trend was scraped
      required: [ rank, title, country, time_range, scraped_at ]

    GoogleTrendsJobResponse:
      type: object
      properties:
        success:
          type: boolean
          description: Whether the job was queued successfully
        job_id:
          type: string
          description: Unique job identifier
        message:
          type: string
          description: Status message
      required: [ success, job_id, message ]

    GoogleTrendsStatusResponse:
      type: object
      properties:
        success:
          type: boolean
          description: Whether the request was successful
        job_id:
          type: string
          description: Job identifier
        status:
          type: string
          enum: [ processing, completed, failed ]
          description: Current job status
        message:
          type: string
          description: Additional status information
      required: [ success, job_id, status ]
